@inproceedings{tera,
author = {Fumio Teraoka and Yasuhiko Yokote and Mario Tokoro},
title = "{A Network Architecture Providing Host Migration Transparency}",
booktitle = "{Proceedings of the Conference on Communications Architecture and Protocols, SIGCOMM 1991}",
pages = {209--220},
month = {August},
year = {1991},
}

@article{10.14778/3476249.3476257,
author = {Sun, Shixuan and Chen, Yuhang and Lu, Shengliang and He, Bingsheng and Li, Yuchen},
title = {ThunderRW: An in-Memory Graph Random Walk Engine},
year = {2021},
issue_date = {July 2021},
publisher = {VLDB Endowment},
volume = {14},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3476249.3476257},
doi = {10.14778/3476249.3476257},
abstract = {As random walk is a powerful tool in many graph processing, mining and learning applications, this paper proposes an efficient in-memory random walk engine named ThunderRW. Compared with existing parallel systems on improving the performance of a single graph operation, ThunderRW supports massive parallel random walks. The core design of ThunderRW is motivated by our profiling results: common RW algorithms have as high as 73.1\% CPU pipeline slots stalled due to irregular memory access, which suffers significantly more memory stalls than the conventional graph workloads such as BFS and SSSP. To improve the memory efficiency, we first design a generic step-centric programming model named Gather-Move-Update to abstract different RW algorithms. Based on the programming model, we develop the step interleaving technique to hide memory access latency by switching the executions of different random walk queries. In our experiments, we use four representative RW algorithms including PPR, DeepWalk, Node2Vec and MetaPath to demonstrate the efficiency and programming flexibility of ThunderRW. Experimental results show that ThunderRW outperforms state-of-the-art approaches by an order of magnitude, and the step interleaving technique significantly reduces the CPU pipeline stall from 73.1\% to 15.0\%.},
journal = {Proc. VLDB Endow.},
month = {jul},
pages = {1992–2005},
numpages = {14}
}

@inproceedings{10.1145/3477132.3483575,
author = {Yang, Ke and Ma, Xiaosong and Thirumuruganathan, Saravanan and Chen, Kang and Wu, Yongwei},
title = {Random Walks on Huge Graphs at Cache Efficiency},
year = {2021},
isbn = {9781450387095},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477132.3483575},
doi = {10.1145/3477132.3483575},
abstract = {Data-intensive applications dominated by random accesses to large working sets fail to utilize the computing power of modern processors. Graph random walk, an indispensable workhorse for many important graph processing and learning applications, is one prominent case of such applications. Existing graph random walk systems are currently unable to match the GPU-side node embedding training speed.This work reveals that existing approaches fail to effectively utilize the modern CPU memory hierarchy, due to the widely held assumption that the inherent randomness in random walks and the skewed nature of graphs render most memory accesses random. We demonstrate that there is actually plenty of spatial and temporal locality to harvest, by careful partitioning, rearranging, and batching of operations. The resulting system, FlashMob, improves both cache and memory bandwidth utilization by making memory accesses more sequential and regular. We also found that a classical combinatorial optimization problem (and its exact pseudo-polynomial solution) can be applied to complex decision making, for accurate yet efficient data/task partitioning. Our comprehensive experiments over diverse graphs show that our system achieves an order of magnitude performance improvement over the fastest existing system. It processes a 58GB real graph at higher per-step speed than the existing system on a 600KB toy graph fitting in the L2 cache.},
booktitle = {Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles},
pages = {311–326},
numpages = {16},
keywords = {random walk, memory, graph computing, cache},
location = {Virtual Event, Germany},
series = {SOSP '21}
}

@inproceedings{10.1145/2507157.2507173,
author = {Kyrola, Aapo},
title = {DrunkardMob: Billions of Random Walks on Just a PC},
year = {2013},
isbn = {9781450324090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2507157.2507173},
doi = {10.1145/2507157.2507173},
abstract = {Random walks on graphs are a staple of many ranking and recommendation algorithms. Simulating random walks on a graph which fits in memory is trivial, but massive graphs pose a problem: the latency of following walks across network in a cluster or loading nodes from disk on-demand renders basic random walk simulation unbearably inefficient. In this work we propose DrunkardMob, a new algorithm for simulating hundreds of millions, or even billions, of random walks on massive graphs, on just a single PC or laptop. Instead of simulating one walk a time it processes millions of them in parallel, in a batch. Based on DrunkardMob and GraphChi we further propose a framework for easily expressing scalable algorithms based on graph walks.},
booktitle = {Proceedings of the 7th ACM Conference on Recommender Systems},
pages = {257–264},
numpages = {8},
keywords = {random walks, graph computation, recommender systems},
location = {Hong Kong, China},
series = {RecSys '13}
}

@inproceedings {254449,
author = {Rui Wang and Yongkun Li and Hong Xie and Yinlong Xu and John C. S. Lui},
title = {{GraphWalker}: An {I/O-Efficient} and {Resource-Friendly} Graph Analytic System for Fast and Scalable Random Walks},
booktitle = {2020 USENIX Annual Technical Conference (USENIX ATC 20)},
year = {2020},
isbn = {978-1-939133-14-4},
pages = {559--571},
url = {https://www.usenix.org/conference/atc20/presentation/wang-rui},
publisher = {USENIX Association},
month = jul
}

@inproceedings{10.1145/3582016.3582025,
author = {Wang, Shuke and Zhang, Mingxing and Yang, Ke and Chen, Kang and Ma, Shaonan and Jiang, Jinlei and Wu, Yongwei},
title = {NosWalker: A Decoupled Architecture for Out-of-Core Random Walk Processing},
year = {2023},
isbn = {9781450399180},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582016.3582025},
doi = {10.1145/3582016.3582025},
abstract = {Out-of-core random walk system has recently attracted a lot of attention as an economical way to run billions of walkers over large graphs. However, existing out-of-core random walk systems are all built upon general out-of-core graph processing frameworks, and hence do not take advantage of the unique properties of random walk applications. Different from traditional graph analysis algorithms, the sampling process of random walk can be decoupled from the processing of the walkers. It enables the system to reserve only pre-sample results in memory, which are typically much smaller than the entire edge set. Moreover, in random walk, it is not the number of walkers but the number of steps moved per second that dominates the overall performance. Thus, with independent walkers, there is no need to process all the walkers simultaneously. In this paper, we present NosWalker, an out-of-core random walk system that replaces the graph oriented scheduling with a decoupled system architecture that provides walker oriented scheduling. NosWalker is able to adaptively generate walkers and flexibly adjust the distribution of reserved pre-sample results in memory. Instead of processing all the walkers at once, NosWalker only tries its best to keep a few walkers able to continuously move forward. Experimental results show that NosWalker can achieve up to two orders of magnitude speedup compared to state-of-the-art out-of-core random walk systems. In particular, NosWalker demonstrates superior performance when the memory capacity can only hold about 10\%-50\% of the graph data, which can be a common case when the user needs to run billions of walkers over large graphs.},
booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
pages = {466–482},
numpages = {17},
keywords = {out-of-core, graph processing, random walk},
location = {Vancouver, BC, Canada},
series = {ASPLOS 2023}
}

@inproceedings{10.1145/3341301.3359634,
author = {Yang, Ke and Zhang, MingXing and Chen, Kang and Ma, Xiaosong and Bai, Yang and Jiang, Yong},
title = {KnightKing: A Fast Distributed Graph Random Walk Engine},
year = {2019},
isbn = {9781450368735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341301.3359634},
doi = {10.1145/3341301.3359634},
abstract = {Random walk on graphs has recently gained immense popularity as a tool for graph data analytics and machine learning. Currently, random walk algorithms are developed as individual implementations and suffer significant performance and scalability problems, especially with the dynamic nature of sophisticated walk strategies.We present KnightKing, the first general-purpose, distributed graph random walk engine. To address the unique interaction between a static graph and many dynamic walkers, it adopts an intuitive walker-centric computation model. The corresponding programming model allows users to easily specify existing or new random walk algorithms, facilitated by a new unified edge transition probability definition that applies across popular known algorithms. With KnightKing, these diverse algorithms benefit from its common distributed random walk execution engine, centered around an innovative rejection-based sampling mechanism that dramatically reduces the cost of higher-order random walk algorithms. Our evaluation confirms that KnightKing brings up to 4 orders of magnitude improvement in executing algorithms that currently can only be afforded with approximation solutions on large graphs.},
booktitle = {Proceedings of the 27th ACM Symposium on Operating Systems Principles},
pages = {524–537},
numpages = {14},
keywords = {graph computing, rejection sampling, random walk},
location = {Huntsville, Ontario, Canada},
series = {SOSP '19}
}

@article{BAP,
author = {Han, Minyang and Daudjee, Khuzaima},
title = {Giraph Unchained: Barrierless Asynchronous Parallel Execution in Pregel-like Graph Processing Systems},
year = {2015},
issue_date = {May 2015},
publisher = {VLDB Endowment},
volume = {8},
number = {9},
issn = {2150-8097},
url = {https://doi.org/10.14778/2777598.2777604},
doi = {10.14778/2777598.2777604},
abstract = {The bulk synchronous parallel (BSP) model used by synchronous graph processing systems allows algorithms to be easily implemented and reasoned about. However, BSP can suffer from poor performance due to stale messages and frequent global synchronization barriers. Asynchronous computation models have been proposed to alleviate these overheads but existing asynchronous systems that implement such models have limited scalability or retain frequent global barriers, and do not always support graph mutations or algorithms with multiple computation phases. We propose barrierless asynchronous parallel (BAP), a new computation model that reduces both message staleness and global synchronization. This enables BAP to overcome the limitations of existing asynchronous models while retaining support for graph mutations and algorithms with multiple computation phases. We present GiraphUC, which implements our BAP model in the open source distributed graph processing system Giraph, and evaluate our system at scale with large real-world graphs on 64 EC2 machines. We show that GiraphUC provides across-the-board performance improvements of up to 5\texttimes{} faster over synchronous systems and up to an order of magnitude faster than asynchronous systems. Our results demonstrate that the BAP model provides efficient and transparent asynchronous execution of algorithms that are programmed synchronously.},
journal = {Proceedings of the VLDB Endowment},
month = {may},
pages = {950–961},
numpages = {12}
}

@inproceedings{AAP,
author = {Fan, Wenfei and Lu, Ping and Luo, Xiaojian and Xu, Jingbo and Yin, Qiang and Yu, Wenyuan and Xu, Ruiqi},
title = {Adaptive Asynchronous Parallelization of Graph Algorithms},
year = {2018},
isbn = {9781450347037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183713.3196918},
doi = {10.1145/3183713.3196918},
abstract = {This paper proposes an Adaptive Asynchronous Parallel (AAP) model for graph computations. As opposed to Bulk Synchronous Parallel (BSP) and Asynchronous Parallel (AP) models, AAP reduces both stragglers and stale computations by dynamically adjusting relative progress of workers. We show that BSP, AP and Stale Synchronous Parallel model (SSP) are special cases of AAP. Better yet, AAP optimizes parallel processing by adaptively switching among these models at different stages of a single execution. Moreover, employing the programming model of GRAPE, AAP aims to parallelize existing sequential algorithms based on fixpoint computation with partial and incremental evaluation. Under a monotone condition, AAP guarantees to converge at correct answers if the sequential algorithms are correct. Furthermore, we show that AAP can optimally simulate MapReduce, PRAM, BSP, AP and SSP. Using real-life and synthetic graphs, we experimentally verify that AAP outperforms BSP, AP and SSP for a variety of graph computations.},
booktitle = {Proceedings of the 2018 International Conference on Management of Data},
pages = {1141–1156},
numpages = {16},
keywords = {parallelization, graph computations, parallel model, church-rosser},
location = {Houston, TX, USA},
series = {SIGMOD '18}
}

@INPROCEEDINGS{Gluon-Async,
author={Dathathri, Roshan and Gill, Gurbinder and Hoang, Loc and Jatala, Vishwesh and Pingali, Keshav and Nandivada, V. Krishna and Dang, Hoang-Vu and Snir, Marc},
booktitle={2019 28th International Conference on Parallel Architectures and Compilation Techniques (PACT)}, 
title={Gluon-Async: A Bulk-Asynchronous System for Distributed and Heterogeneous Graph Analytics}, 
year={2019},
volume={},
number={},
pages={15-28},
doi={10.1109/PACT.2019.00010}
}

@inproceedings{Pregel,
author = {Malewicz, Grzegorz and Austern, Matthew H. and Bik, Aart J.C and Dehnert, James C. and Horn, Ilan and Leiser, Naty and Czajkowski, Grzegorz},
title = {Pregel: A System for Large-Scale Graph Processing},
year = {2010},
isbn = {9781450300322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807167.1807184},
doi = {10.1145/1807167.1807184},
abstract = {Many practical computing problems concern large graphs. Standard examples include the Web graph and various social networks. The scale of these graphs - in some cases billions of vertices, trillions of edges - poses challenges to their efficient processing. In this paper we present a computational model suitable for this task. Programs are expressed as a sequence of iterations, in each of which a vertex can receive messages sent in the previous iteration, send messages to other vertices, and modify its own state and that of its outgoing edges or mutate graph topology. This vertex-centric approach is flexible enough to express a broad set of algorithms. The model has been designed for efficient, scalable and fault-tolerant implementation on clusters of thousands of commodity computers, and its implied synchronicity makes reasoning about programs easier. Distribution-related details are hidden behind an abstract API. The result is a framework for processing large graphs that is expressive and easy to program.},
booktitle = {Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data},
pages = {135–146},
numpages = {12},
keywords = {graph algorigthms, distributed computing},
location = {Indianapolis, Indiana, USA},
series = {SIGMOD '10}
}

@inproceedings{10.1145/2741948.2741970,
author = {Chen, Rong and Shi, Jiaxin and Chen, Yanzhe and Chen, Haibo},
title = {PowerLyra: Differentiated Graph Computation and Partitioning on Skewed Graphs},
year = {2015},
isbn = {9781450332385},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2741948.2741970},
doi = {10.1145/2741948.2741970},
abstract = {Natural graphs with skewed distribution raise unique challenges to graph computation and partitioning. Existing graph-parallel systems usually use a "one size fits all" design that uniformly processes all vertices, which either suffer from notable load imbalance and high contention for high-degree vertices (e.g., Pregel and GraphLab), or incur high communication cost and memory consumption even for low-degree vertices (e.g., PowerGraph and GraphX).In this paper, we argue that skewed distribution in natural graphs also calls for differentiated processing on high-degree and low-degree vertices. We then introduce PowerLyra, a new graph computation engine that embraces the best of both worlds of existing graph-parallel systems, by dynamically applying different computation and partitioning strategies for different vertices. PowerLyra further provides an efficient hybrid graph partitioning algorithm (hybrid-cut) that combines edge-cut and vertex-cut with heuristics. Based on PowerLyra, we design locality-conscious data layout optimization to improve cache locality of graph accesses during communication. PowerLyra is implemented as a separate computation engine of PowerGraph, and can seamlessly support various graph algorithms. A detailed evaluation on two clusters using graph-analytics and MLDM (machine learning and data mining) applications show that PowerLyra outperforms PowerGraph by up to 5.53X (from 1.24X) and 3.26X (from 1.49X) for real-world and synthetic graphs accordingly, and is much faster than other systems like GraphX and Giraph, yet with much less memory consumption. A porting of hybrid-cut to GraphX further confirms the efficiency and generality of PowerLyra.},
booktitle = {Proceedings of the Tenth European Conference on Computer Systems},
articleno = {1},
numpages = {15},
location = {Bordeaux, France},
series = {EuroSys '15}
}

@inproceedings{10.5555/2387880.2387883,
author = {Gonzalez, Joseph E. and Low, Yucheng and Gu, Haijie and Bickson, Danny and Guestrin, Carlos},
title = {PowerGraph: Distributed Graph-Parallel Computation on Natural Graphs},
year = {2012},
isbn = {9781931971966},
publisher = {USENIX Association},
address = {USA},
abstract = {Large-scale graph-structured computation is central to tasks ranging from targeted advertising to natural language processing and has led to the development of several graph-parallel abstractions including Pregel and GraphLab. However, the natural graphs commonly found in the real-world have highly skewed power-law degree distributions, which challenge the assumptions made by these abstractions, limiting performance and scalability.In this paper, we characterize the challenges of computation on natural graphs in the context of existing graph-parallel abstractions. We then introduce the PowerGraph abstraction which exploits the internal structure of graph programs to address these challenges. Leveraging the PowerGraph abstraction we introduce a new approach to distributed graph placement and representation that exploits the structure of power-law graphs. We provide a detailed analysis and experimental evaluation comparing PowerGraph to two popular graph-parallel systems. Finally, we describe three different implementation strategies for PowerGraph and discuss their relative merits with empirical evaluations on large-scale real-world problems demonstrating order of magnitude gains.},
booktitle = {Proceedings of the 10th USENIX Conference on Operating Systems Design and Implementation},
pages = {17–30},
numpages = {14},
location = {Hollywood, CA, USA},
series = {OSDI'12}
}

@inproceedings{10.5555/3026877.3026901,
author = {Zhu, Xiaowei and Chen, Wenguang and Zheng, Weimin and Ma, Xiaosong},
title = {Gemini: A Computation-Centric Distributed Graph Processing System},
year = {2016},
isbn = {9781931971331},
publisher = {USENIX Association},
address = {USA},
abstract = {Traditionally distributed graph processing systems have largely focused on scalability through the optimizations of inter-node communication and load balance. However, they often deliver unsatisfactory overall processing efficiency compared with shared-memory graph computing frameworks. We analyze the behavior of several graph-parallel systems and find that the added overhead for achieving scalability becomes a major limiting factor for efficiency, especially with modern multi-core processors and high-speed interconnection networks.Based on our observations, we present Gemini, a distributed graph processing system that applies multiple optimizations targeting computation performance to build scalability on top of efficiency. Gemini adopts (1) a sparse-dense signal-slot abstraction to extend the hybrid push-pull computation model from shared-memory to distributed scenarios, (2) a chunk-based partitioning scheme enabling low-overhead scaling out designs and locality-preserving vertex accesses, (3) a dual representation scheme to compress accesses to vertex indices, (4) NUMA-aware sub-partitioning for efficient intra-node memory accesses, plus (5) locality-aware chunking and fine-grained work-stealing for improving both internode and intra-node load balance, respectively. Our evaluation on an 8-node high-performance cluster (using five widely used graph applications and five real-world graphs) shows that Gemini significantly outperforms all well-known existing distributed graph processing systems, delivering up to 39.8\texttimes{} (from 8.91\texttimes{}) improvement over the fastest among them.},
booktitle = {Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation},
pages = {301–316},
numpages = {16},
location = {Savannah, GA, USA},
series = {OSDI'16}
}

@inproceedings{Gluon,
author = {Dathathri, Roshan and Gill, Gurbinder and Hoang, Loc and Dang, Hoang-Vu and Brooks, Alex and Dryden, Nikoli and Snir, Marc and Pingali, Keshav},
title = {Gluon: A Communication-Optimizing Substrate for Distributed Heterogeneous Graph Analytics},
year = {2018},
isbn = {9781450356985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3192366.3192404},
doi = {10.1145/3192366.3192404},
abstract = {This paper introduces a new approach to building distributed-memory graph analytics systems that exploits heterogeneity in processor types (CPU and GPU), partitioning policies, and programming models. The key to this approach is Gluon, a communication-optimizing substrate. Programmers write applications in a shared-memory programming system of their choice and interface these applications with Gluon using a lightweight API. Gluon enables these programs to run on heterogeneous clusters and optimizes communication in a novel way by exploiting structural and temporal invariants of graph partitioning policies. To demonstrate Gluon’s ability to support different programming models, we interfaced Gluon with the Galois and Ligra shared-memory graph analytics systems to produce distributed-memory versions of these systems named D-Galois and D-Ligra, respectively. To demonstrate Gluon’s ability to support heterogeneous processors, we interfaced Gluon with IrGL, a state-of-the-art single-GPU system for graph analytics, to produce D-IrGL, the first multi-GPU distributed-memory graph analytics system. Our experiments were done on CPU clusters with up to 256 hosts and roughly 70,000 threads and on multi-GPU clusters with up to 64 GPUs. The communication optimizations in Gluon improve end-to-end application execution time by ∼2.6\texttimes{} on the average. D-Galois and D-IrGL scale well and are faster than Gemini, the state-of-the-art distributed CPU graph analytics system, by factors of ∼3.9\texttimes{} and ∼4.9\texttimes{}, respectively, on the average.},
booktitle = {Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {752–768},
numpages = {17},
keywords = {GPUs, communication optimizations, heterogeneous architectures, Distributed-memory graph analytics, big data},
location = {Philadelphia, PA, USA},
series = {PLDI 2018}
}

@inproceedings{10.5555/3277180.3277185,
author = {Iyer, Anand Padmanabha and Panda, Aurojit and Chowdhury, Mosharaf and Akella, Aditya and Shenker, Scott and Stoica, Ion},
title = {Monarch: Gaining Command on Geo-Distributed Graph Analytics},
year = {2018},
publisher = {USENIX Association},
address = {USA},
abstract = {A number of existing and emerging application scenarios generate graph-structured data in a geo-distributed fashion. Although there is a lot of interest in distributed graph processing systems, none of them support geo-distributed graph processing. Geo-distributed analytics, on the other hand, has not focused on iterative workloads such as distributed graph processing.In this paper, we look at the problem of efficient geo-distributed graph analytics. We find that optimizing the iterative processing style of graph-parallel systems is the key to achieving this goal rather than extending existing geo-distributed techniques to graph processing. Based on this, we discuss our proposal on building MONARCH, the first system to our knowledge that focuses on geo-distributed graph processing. Our preliminary evaluation of MONARCH shows encouraging results.},
booktitle = {Proceedings of the 10th USENIX Conference on Hot Topics in Cloud Computing},
pages = {5},
numpages = {1},
location = {Boston, MA, USA},
series = {HotCloud'18}
}

@INPROCEEDINGS{8486361,
  author={Liu, Shuhao and Chen, Li and Li, Baochun and Carnegie, Aiden},
  booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications}, 
  title={A Hierarchical Synchronous Parallel Model for Wide-Area Graph Analytics}, 
  year={2018},
  volume={},
  number={},
  pages={531-539},
  doi={10.1109/INFOCOM.2018.8486361}}

@inproceedings{10.1145/3397271.3401157,
author = {Yuan, Ye and Ma, Delong and Wen, Zhenyu and Ma, Yuliang and Wang, Guoren and Chen, Lei},
title = {Efficient Graph Query Processing over Geo-Distributed Datacenters},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401157},
doi = {10.1145/3397271.3401157},
abstract = {Graph queries have emerged as one of the fundamental techniques to support modern search services, such as PageRank web search, social networking search and knowledge graph search. As such graphs are maintained globally and very huge (e.g., billions of nodes), we need to efficiently process graph queries across multiple geographically distributed datacenters, running geo-distributed graph queries. Existing graph computing frameworks may not work well for geographically distributed datacenters, because they implement a Bulk Synchronous Parallel model that requires excessive inter-datacenter transfers, thereby introducing extremely large latency for query processing. In this paper, we propose GeoGraph --a universal framework to support efficient geo-distributed graph query processing based on clustering datacenters and meta-graph, while reducing the inter-datacenter communication. Our new framework can be applied to many types of graph algorithms without any modification. The framework is developed on the top of Apache Giraph. The experiments were conducted by applying four important graph queries, i.e., shortest path, graph keyword search, subgraph isomorphism and PageRank. The evaluation results show that our proposed framework can achieve up to 82\% faster convergence, 42\% lower WAN bandwidth usage, and 45\% less total monetary cost for the four graph queries, with input graphs stored across ten geo-distributed datacenters.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {619–628},
numpages = {10},
keywords = {graph search, datacenters, geo-distributed},
location = {Virtual Event, China},
series = {SIGIR '20}
}

@article{334,
title	= {The Anatomy of a Large-Scale Hypertextual Web Search Engine},
author	= {Sergey Brin and Lawrence Page},
year	= {1998},
URL	= {http://www-db.stanford.edu/~backrub/google.html},
journal	= {Computer Networks},
pages	= {107-117},
volume	= {30}
}

@inproceedings{10.5555/2535461.2535468,
author = {Bronson, Nathan and Amsden, Zach and Cabrera, George and Chakka, Prasad and Dimov, Peter and Ding, Hui and Ferris, Jack and Giardullo, Anthony and Kulkarni, Sachin and Li, Harry and Marchukov, Mark and Petrov, Dmitri and Puzar, Lovro and Song, Yee Jiun and Venkataramani, Venkat},
title = {TAO: Facebook's Distributed Data Store for the Social Graph},
year = {2013},
publisher = {USENIX Association},
address = {USA},
abstract = {We introduce a simple data model and API tailored for serving the social graph, and TAO, an implementation of this model. TAO is a geographically distributed data store that provides efficient and timely access to the social graph for Facebook's demanding workload using a fixed set of queries. It is deployed at Facebook, replacing memcache for many data types that fit its model. The system runs on thousands of machines, is widely distributed, and provides access to many petabytes of data. TAO can process a billion reads and millions of writes each second.},
booktitle = {Proceedings of the 2013 USENIX Conference on Annual Technical Conference},
pages = {49–60},
numpages = {12},
location = {San Jose, CA},
series = {USENIX ATC'13}
}

@inproceedings{10.1145/3331184.3331252,
author = {Lu, Xiaolu and Pramanik, Soumajit and Saha Roy, Rishiraj and Abujabal, Abdalghani and Wang, Yafang and Weikum, Gerhard},
title = {Answering Complex Questions by Joining Multi-Document Evidence with Quasi Knowledge Graphs},
year = {2019},
isbn = {9781450361729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331184.3331252},
doi = {10.1145/3331184.3331252},
abstract = {Direct answering of questions that involve multiple entities and relations is a challenge for text-based QA. This problem is most pronounced when answers can be found only by joining evidence from multiple documents. Curated knowledge graphs (KGs) may yield good answers, but are limited by their inherent incompleteness and potential staleness. This paper presents QUEST, a method that can answer complex questions directly from textual sources on-the-fly, by computing similarity joins over partial results from different documents. Our method is completely unsupervised, avoiding training-data bottlenecks and being able to cope with rapidly evolving ad hoc topics and formulation style in user questions. QUEST builds a noisy quasi KG with node and edge weights, consisting of dynamically retrieved entity names and relational phrases. It augments this graph with types and semantic alignments, and computes the best answers by an algorithm for Group Steiner Trees. We evaluate QUEST on benchmarks of complex questions, and show that it substantially outperforms state-of-the-art baselines.},
booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {105–114},
numpages = {10},
keywords = {complex questions, group steiner trees, direct answers, question answering from the web},
location = {Paris, France},
series = {SIGIR'19}
}

@inproceedings{10.1145/2723372.2735365,
author = {Vulimiri, Ashish and Curino, Carlo and Godfrey, Philip Brighten and Jungblut, Thomas and Karanasos, Konstantinos and Padhye, Jitendra and Varghese, George},
title = {WANalytics: Geo-Distributed Analytics for a Data Intensive World},
year = {2015},
isbn = {9781450327589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723372.2735365},
doi = {10.1145/2723372.2735365},
abstract = {Many large organizations collect massive volumes of data each day in a geographically distributed fashion, at data centers around the globe. Despite their geographically diverse origin the data must be processed and analyzed as a whole to extract insight. We call the problem of supporting large-scale geo-distributed analytics Wide-Area Big Data (WABD). To the best of our knowledge, WABD is currently addressed by copying all the data to a central data center where the analytics are run. This approach consumes expensive cross-data center bandwidth and is incompatible with data sovereignty restrictions that are starting to take shape. We instead propose WANalytics, a system that solves the WABD problem by orchestrating distributed query execution and adjusting data replication across data centers in order to minimize bandwidth usage, while respecting sovereignty requirements. WANalytics achieves an up to 360x reduction in data transfer cost when compared to the centralized approach on both real Microsoft production workloads and standard synthetic benchmarks, including TPC-CH and Berkeley Big-Data. In this demonstration, attendees will interact with a live geo-scale multi-data center deployment of WANalytics, allowing them to experience the data transfer reduction our system achieves, and to explore how it dynamically adapts execution strategy in response to changes in the workload and environment.},
booktitle = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
pages = {1087–1092},
numpages = {6},
keywords = {federation, olap, geo-distribution, sovereignty, analytics},
location = {Melbourne, Victoria, Australia},
series = {SIGMOD '15}
}

@misc{snapnets,
  author       = {Jure Leskovec and Andrej Krevl},
  title        = {{SNAP Datasets}: {Stanford} Large Network Dataset Collection},
  howpublished = {\url{http://snap.stanford.edu/data}},
  month        = jun,
  year         = 2014
}

@article{SBM,
  title     = {Stochastic blockmodels: First steps},
  author    = {Holland, Paul W and Laskey, Kathryn Blackmond and Leinhardt, Samuel},
  journal   = {Social networks},
  volume    = {5},
  number    = {2},
  pages     = {109--137},
  year      = {1983},
  publisher = {Elsevier}
}